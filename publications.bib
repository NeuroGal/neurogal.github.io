@article{vishne_2023,
title = {Distinct ventral stream and prefrontal cortex representational dynamics during sustained conscious visual perception.},
author = {Vishne, Gal and Gerber, Edden M and Knight, Robert T and Deouell, Leon Y},
pages = {112752},
url = {https://linkinghub.elsevier.com/retrieve/pii/S2211124723007635},
year = {2023},
month = {jul},
day = {25},
urldate = {2023-12-10},
journal = {Cell reports},
volume = {42},
number = {7},
issn = {22111247},
doi = {10.1016/j.celrep.2023.112752},
pmid = {37422763},
pmcid = {PMC10530642},
abstract = {Instances of sustained stationary sensory input are ubiquitous. However, previous work focused almost exclusively on transient onset responses. This presents a critical challenge for neural theories of consciousness, which should account for the full temporal extent of experience. To address this question, we use intracranial recordings from ten human patients with epilepsy to view diverse images of multiple durations. We reveal that, in sensory regions, despite dramatic changes in activation magnitude, the distributed representation of categories and exemplars remains sustained and stable. In contrast, in frontoparietal regions, we find transient content representation at stimulus onset. Our results highlight the connection between the anatomical and temporal correlates of experience. To the extent perception is sustained, it may rely on sensory representations and to the extent perception is discrete, centered on perceptual updating, it may rely on frontoparietal representations. Copyright \copyright 2023 The Author(s). Published by Elsevier Inc. All rights reserved.}
}
@article{vishne_2021,
title = {Slow update of internal representations impedes synchronization in autism.},
author = {Vishne, Gal and Jacoby, Nori and Malinovitch, Tamar and Epstein, Tamir and Frenkel, Or and Ahissar, Merav},
pages = {5439},
url = {http://dx.doi.org/10.1038/s41467-021-25740-y},
year = {2021},
month = {sep},
day = {14},
urldate = {2023-12-10},
journal = {Nature Communications},
volume = {12},
number = {1},
doi = {10.1038/s41467-021-25740-y},
pmid = {34521851},
pmcid = {PMC8440645},
abstract = {Autism is a neurodevelopmental disorder characterized by impaired social skills, motor and perceptual atypicalities. These difficulties were explained within the Bayesian framework as either reflecting oversensitivity to prediction errors or - just the opposite - slow updating of such errors. To test these opposing theories, we administer paced finger-tapping, a synchronization task that requires use of recent sensory information for fast error-correction. We use computational modelling to disentangle the contributions of error-correction from that of noise in keeping temporal intervals, and in executing motor responses. To assess the specificity of tapping characteristics to autism, we compare performance to both neurotypical individuals and individuals with dyslexia. Only the autism group shows poor sensorimotor synchronization. Trial-by-trial modelling reveals typical noise levels in interval representations and motor responses. However, rate of error correction is reduced in autism, impeding synchronization ability. These results provide evidence for slow updating of internal representations in autism. \copyright 2021. The Author(s).}
}
@book{na_2022,
title = {Levels of Reality in Science and Philosophy: Re-examining the Multi-level Structure of Reality},
editor = {Ioannidis, Stavros and Vishne, Gal and Hemmo, Meir and Shenker, Orly},
series = {Jerusalem studies in philosophy and history of science},
publisher = {Springer International Publishing},
url = {https://link.springer.com/10.1007/978-3-030-99425-9},
year = {2022},
urldate = {2023-12-10},
isbn = {978-3-030-99424-2},
issn = {2524-4248},
doi = {10.1007/978-3-030-99425-9},
address = {Cham},
}
@article{auerbachasch_2023,
title = {Decoding object categories from {EEG} during free viewing reveals early information evolution compared to passive viewing},
author = {Auerbach-Asch, Carmel Ruth and Vishne, Gal and Wertheimer, Oded and Deouell, Leon Y},
url = {http://biorxiv.org/lookup/doi/10.1101/2023.06.28.546397},
year = {2023},
month = {jun},
day = {30},
urldate = {2023-12-10},
journal = {BioRxiv},
doi = {10.1101/2023.06.28.546397},
abstract = {Object processing is fundamental to visual perception, and understanding its neural substrates informs many cognitive and computational visual processing models. Thus far, most human studies have used passive viewing paradigms, during which self-driven behavior, such as eye movements, is constrained, and brain activity is evoked by abrupt stimuli onsets. This artificial dissociation of perception and action ignores the natural dynamics of visual processing. Thus, conclusions based on such passive viewing paradigms may not apply to active vision. Here, we study the human neural correlates of category representations during active visual processing by time-locking {EEG} to self-driven fixations during visual search for natural objects. We combine the deconvolution of overlapping responses to consecutive fixations with multivariate pattern analysis ({MVPA}) to decode object categories from responses to single fixation. We bridge the active and passive viewing literature by comparing the temporal dynamics of multivariate object representations during free visual search (active viewing) and rapid serial visual presentation (passive viewing), leveraging the high temporal resolution of {EEG}. We found that categorical information, at different levels of abstraction, can be decoded from single fixations during natural visual processing, and cross-condition decoding revealed that object representations are similar between active and passive viewing conditions. However, representational dynamics emerge significantly earlier in active compared to passive conditions, likely due to the availability of predictive information in free viewing. We highlight methodological considerations for combining {MVPA} with deconvolution methods.}
}

